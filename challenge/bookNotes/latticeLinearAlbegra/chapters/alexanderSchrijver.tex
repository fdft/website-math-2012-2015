 \chapter{Book: Theory of Linear and Integer Programming}

Most text/math came from \cite{schrijver}.


\section{Theory of lattices and linear diophantine equations}



\begin{definition}
Elementary unimodular column operations
\begin{enumerate}
	\item swap two columns
	\item multiplying a column by -1
	\item adding an integral multiple of one column to another column.
\end{enumerate}
\end{definition}


\begin{definition}
A full row rank matrix is in Hermite normal form if it is the form [B 0] where B is nonsingular, lower triangular, nonnegative matrix, and each row has a unique maximum entry located on the main diagonal. 
\end{definition}


\begin{theorem}(Hermite normal form theorem)
Each rational matrix of full row rank can be brought into Hermite normal form by a series of elementary column operations.
\end{theorem}
\begin{proof}
Let A be integral, wlog. By induction, assume we transformed A by elementary column operations to the form 
$\left(\begin{matrix} B & 0 \\ C & D \end{matrix}\right)$ where B is lower triangular and with positive diagonal. With elm. column operations we can modify D so its first row is nonegative and the sum $d_{11} + \dots + d_{1k}$ is as small as possible. Assume that $d_{11} \leq \dots \leq d_{1k}$. Then $d_{11} >0$ b/c A is full row rank. If $d_{12} > 0$ then subtract the 2nd column of D from the first, then the first row will have smaller sum, a contradiction, and so $d_{12} = \dots = d_{1k} = 0$. By repeating for each row, we transform A into [B 0] where B is lower triangular. Then add multiple of column j to $i < j$ to get it in HNF.
\end{proof}


\begin{corollary}
Let A be rational, b is rational. The System Ax = b as in integral solution x iff yb is an integer for each rational row vector y for which yA is integral.
\end{corollary}
\begin{proof}
$\Leftarrow:$ For a contradiction, assume yA is integral, but yb is not. But x is integer and yAx = yb so (integer) = non-integer.

$\Rightarrow:$ Assume yb is integer when yA is integral. Ax = b has a real solution, otherwise we could find y s.t. yA = 0, yB = 1/2 (by linear algebra). So we can now assume A has full row rank. Because both sides of the equivalence are invariant under elm column operations, we can assume A is in HNF [B 0]. B/c $B^{-1}[B 0] = [I 0]$ is integral, $B^{-1}b$ is integral by assumption (applied to each row).

So $x = (B^{-1}b, 0)^T$ is the integral solution to $[B \;0] = b$.
\end{proof}


\begin{corollary}
Let A be integral $m \times n$  full row rank matrix. The following are equivalent
\begin{enumerate}
	\item the gcd of the subdeterminants of A or order m is 1.
	\item the system Ax=b has an integral solution x, for each integral vector b.
	\item for each vector y, if yA is integral then y is integral
\end{enumerate}
\end{corollary}
\begin{proof}
1,2,3 are invariant under elm column operations on A. So assume A is in HNF [B 0]. 1,2,3 are equivalent to B=I.
\end{proof}



\begin{theorem}
The following are equivalent for a nonsingular rational matrix U of order n
\begin{enumerate}
	\item U is unimodular.
	\item $U^{-1}$ is unomdular
	\item the lattice generated by the columns of U is $\Z^n$
	\item U has the identity matrix as HNF.
	\item U comes from I by elm column operations.
\end{enumerate}
\end{theorem}
\begin{proof}
1 $\leftrightarrow$ 2 is clear.

3 $\leftrightarrow$ 4 $\leftrightarrow$ 5 is clear by taking the HNF.

5 $\leftrightarrow$ 1 is clear.

1 $\leftrightarrow$ 4: if B is the HNF of U then B is integral and $|det(B)| = |det(U)| =1 $ But B is triangular. Thus $B = I$.
\end{proof}



\begin{corollary}
A and A' are nonsingular. The following are equivalent
\begin{enumerate}
	\item columns of A and A' generate the same lattice.
	\item A' comes from A by elm. column operations.
	\item A'=AU for some unimodular matrix U.
\end{enumerate}
\end{corollary}
\begin{proof}
2 $\leftrightarrow$ 3 is clear.

1 $\leftrightarrow$ 3: let B, B' be the HNF of A, A'. so let A = BU, A'=B'U'. But HNF is unique (we skipped the proof) for the lattice so B = B'. Then $AU^{-1}U' = BU' = A'$
\end{proof}

\begin{corollary}
If A, B are nonsingular, and each column of B is in the lattice generated by the columns of A, then det(B) is an integral multiple of det(A). Furthermore, $|det(A)| = |det(B)|$ iff the lattice generated by the columns of A = lattice generated by B.
\end{corollary}
\begin{proof}
So $B = A U$ where U is just integral. So $|det(B)| = |det(A)| |det(U)|$. And $|det(A)| = |det(B)|$ iff U is unimodular.
\end{proof}

\section{Algorithms for linear diophantine equations}

\subsection{EA}

\begin{algorithm}                      
\caption{(Rational) Euclidean Algorithm}
\label{alg:EuclideanAlgorithm2}
\begin{algorithmic}                    
\REQUIRE rationals $a, b$.
\ENSURE $gcd(a,b)$
\STATE 1) let $A = \left(\begin{matrix} a & b \\ 1 & 0 \\ 0 & 1 \end{matrix} \right)$
\STATE 2) Let $A_k = \left(\begin{matrix} a_k & b_k \\ y_k & g_k \\ e_k & z_k \end{matrix} \right)$. Then find $A_k$ by the following rule
\STATE \;\;\;\; If k is even and $b_k > 0$: subtract $\floor{a_k/b_k}$ times the second column of $A_k$ from the 1st.
\STATE \;\;\;\; If k is odd and $a_k >0$: subtract $\floor{b_k/a_k}$ times the first column of $A_k$ from the 2nd. 
\end{algorithmic}
\end{algorithm}

This is done for $k=1..N$ when $a_N=0$ or $b_N=0$. The gcd of the first row of A does not change. We also get the extended EA form. To see this, note that $(1, -a, -b)A_k = (0,0)$. This means
\begin{align*}
	y_ka + e_kb & = a_k \\
	g_ka + z_kb & = b_k
\end{align*}

and so depending on if $a_N = 0$ or $b_N = 0$ one equation gives the gcd in terms of a and b.


\begin{corollary}
A linear diophantine equation with rational coefficients can be solved in polynomial time.
\end{corollary}
\begin{proof}
Let $a_1z_1 + \dots + a_nz_n = b$. (the a's are known and scaled to integers). If n=1, this is easy. For $n \geq 2$, let $a' = gcd(a_1, a_2) = a_1 y + a_2 e$, where y and e are integers. 
Now solve $a'z' + a_3z_3 + \dots + a_nz_n = b$. If this has no integral solution, neither does the first one. If $(z', z_3, \dots, z_n)$  is a solution, then the first solution is $z_1= yz', z_2 = ez', z_i = z_i$.
\end{proof}


\subsection{HNF}

We will describe the algo to find the HNF.

Let A be $m \times n$ of full row rank. Let M be the abs. value of the determinant of an arbitarary submatrix of A or rank m. The columns of A generate the same lattice as $A' = [A | M*I]$ (Why: A has full rank square submatrix B with det(B) = +-B, and $det(B) B^{-1}$ is integral. So BX=MI has an integer solution X.)

My elm. col. operations, we can reduce $a_{ij}$ mod M. For k = 0..m consider the matrix
\[
\left( \begin{tabular}{c|c|ccc}
B &0 & 0 & \dots & 0\\
C &D & 0& \dots & 0\\
   &   & M& 0      & 0 \\
   &   & 0& $\ddots$ & 0  \\
   &   & 0& \dots  &M
\end{tabular}\right)
\]

Where B is lower triangular $k \times k$, C is $(m-k)\times k$, D is $(m-k) \times (n+1)$, and the whole matrix is $m \times (m+n)$ (so the first row of d is $(stuff, M)$.

Then, repeatedly do while the first row of D contains more than 1 non-zero: if there are $d_{1i} \geq d_{1j} > 0$ then subtract $\floor{d_{1i}/d_{1j}}$ times the jth column of D from the ith column of D. Then add integral multiples of the last $m-k-1$ columns  to reduce all entries in D modulo M.

Then increase k. When k=m, $A' = [B, 0]$. Then we can make B nonnegative and each row mod the diagional. 

Deleting the last m columns (which are now zero) give the HNF of A.

\section{Basis reduction}
We will prove the main algorithm all in 1 shot!
\begin{theorem}(Basis reduction method)
there exists a polynomial algorithm which, for given positive definite rational matrix D, finds a basis $b_1, \dots, b_n$ for the lattice $\Z^n$. st
\[ \snorm{b_1}\dots \snorm{b_n} \leq 2^{n(n-1)/4} det(D)^{1/2} \]
where $\snorm{x} = \sqrt{x^TDx}$.
\end{theorem}
\begin{proof}
We can assume D is integer. Also, we also define orthogonality w.r.t. $x^TDy =0$ and take inner products w.r.t. $D$.

Start off with $b_i$ the std. basis vectors.

Step 1: Let $B^*$ be the GS of B (take inner products w.r.t D).

Step 2: Write $B = B^* V$ for some upper triangular matrix V with 1's on the diagonal (b/c $b_i = \lambda_1 b^*_1 + \dots \lambda_{i-1}b^*_{i-1} + b^*_i$). Then do elm column operations that change V into an upper triangular with 1's on the diagonal and all other entries at most 1/2 is absolute value. This does not change the GS orthogonalization of the b's.

Step 3: If $\snorm{b*_i}^2 \geq 2\snorm{b^*_{i+1}}^2$ then exchange $b_i$ and $b_{i+1}$ and goto step 1. Else stop.

The author goes on to prove the algorithm stops, is correct, is polynomial time, and gives the same identities as other others (in more generality). But I stop here--BD.
\end{proof}



\begin{corollary}
There exists a polynomial algo which, for given nonsingular rational matrix A, finds a basis $b_1, \dots, b_n$ for the lattice generated by the columns of A s.t. \[\norm{b_1}\dots\norm{b_n} \leq 2^{n(n-1)/4}|det(A)|\]
\end{corollary}
\begin{proof}
Set $D=A^TA$ and apply the last theorem. This gives a basis $b_1, \dots, b_n$ for $\Z^n$ s.t.
\begin{align*}
\norm{Ab_1}\dots\norm{Ab_n} &= \sqrt{b_1^TDb_1} \dots \sqrt{b_n^TDb_n} 
	& \leq 2^{n(n-1)/4}det(D)^{1/2}
	& = 2^{n(n-1)/4}|det(A)|
\end{align*}
The vectors$\norm{Ab_1}, \dots, \norm{Ab_n}$ form a basis for the lattice.
\end{proof}

\subsection{Application: Finding shortest nonzero vector in a lattice}

From Minkowski, any n-dim lattice has a nonzero vector b with 
\[ \norm{b} \leq 2 (\frac{det(\Lambda)}{V_n})^{1/n}\] 
where $V_n$ is the volume of the n-dim unit ball.  No poly-time algo is know to find this b. It is thought that finding the shortest nonzero vector in a lattice is NP-complete. But we can find a `longer short vector' in a lattice, by taking the shortest vector in the basis constructed there.


\begin{corollary}
There exists a poly-algo which, given a nonsingular rational matrix A, finds a nonzero vector b in the lattice generated by the columns of A with $\norm{b} \leq 2^{n(n-1)/4}det(\Lambda)^{1/n}$
\end{corollary}
\begin{proof}
From the last corollary, 
\begin{align*}
\norm{Ab_1} &= \snorm{b_1}
	&= (\Pi_{k=1}^n \snorm{b*_1}^{1/n}
	&\leq (\Pi_{k=1}^n 2^{(k-1)/2}\snorm{b^*_k})^{1/n}
	& = (2^{n(n-1)/4}det(\Lambda))^{1/2}
\end{align*}
\end{proof}

So we can use LLL to find a short vonzero vector, but generally NOT THE SHORTEST.



\subsection{Application: Finding shortest nonzero vector in a lattice}
We saw this one in the other book already. Nothing new.

\subsection{Application: Finding HNF}

Let A be a nonsingular integral matrix of order n. Let $M = \ceil{2^{n(n-1)/4}|det(A)|}$. Let C arise from A by multiplying the ith row of A by $M^{n-i}$ for $i=1, \dots, n$.

We can find in poly-time a basis $b_1, \dots, b_n$ for the lattice generated by the columns of C s.t.
\[\norm{b_1}\dots\norm{b_n} \leq 2^{n(n-1)/4}|det(C)| =  2^{n(n-1)/4}M^{n(n-1)/2}|det(A)|\]

These vectors can be reordered in such a way that the matrix $[b_1,\dots, b_n]$ is lower triangular. We can assume (by reordering) the jth corrdinate of $b_j$ is at least $M^{n-j}$ in abs. value, and so $\norm{b_j} \geq M^{n-j}$. Why?: Assume the ith coordinate of $b_{k}$ is nonzero for some $1 \leq i < k \leq n$. Then $\norm{b_k} > M^{n-i}M \geq M^{n-k}M$ and
\[ \norm{b_1}\dots\norm{b_n}  > (\Pi_{j=1}^n M^{n-j})M \geq 2^{n(n-1)/2}M^{n(n-1)/2)}|det(A)| \]
a contradiction to what is above.

So $b_1, \dots, b_n$ can be reordered s.t. the matrix B is lower triangular. Then we can multiply by elm. column operations to make B in HNF (nonnegagive, largest row element on the diagional,etc).

Dividing the HNF's jth row by $M^{n-j}$ for each j gives the HNF of A.
